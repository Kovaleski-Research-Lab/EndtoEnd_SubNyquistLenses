{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807c8ae-3458-477f-82ff-9d255fc1e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning import seed_everything\n",
    "from torchmetrics.functional import mean_squared_error as mse\n",
    "from torchmetrics.functional import peak_signal_noise_ratio as psnr\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from torchmetrics import ConfusionMatrix, F1Score, Accuracy, Precision, Recall, ConfusionMatrix\n",
    "sys.path.append('../')\n",
    "from utils import parameter_manager, model_loader\n",
    "from core import datamodule, lrn, modulator, propagator, classifiers, cooperative\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "\n",
    "f1 = F1Score(task = 'multiclass', num_classes = 10, top_k = 1).cpu()\n",
    "acc = Accuracy(task = 'multiclass', num_classes = 10, top_k = 1).cpu()\n",
    "prec = Precision(task = 'multiclass', num_classes = 10, top_k = 1).cpu()\n",
    "rec = Recall(task = 'multiclass', num_classes = 10, top_k = 1).cpu()\n",
    "cfm = ConfusionMatrix(task = 'multiclass', num_classes=10, top_k = 1).cpu()\n",
    "#logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6f6c3-b236-4c11-8918-264d8321ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "params = yaml.load(open('../config.yaml'), Loader = yaml.FullLoader)\n",
    "params['batch_size'] = 1\n",
    "params['distance'] = torch.tensor(0.60264)\n",
    "\n",
    "\n",
    "pm = parameter_manager.Parameter_Manager(params = params)\n",
    "#pm.path_data = '/cgi/data/erdc_xai/resolution_constrained_deep_optics/data/'\n",
    "#pm.collect_params()\n",
    "\n",
    "# Load in the test dataset\n",
    "pm.data_split = \"mnist_1000perClass\"\n",
    "datamod = datamodule.select_data(pm.params_datamodule)\n",
    "datamod.setup()\n",
    "dataloader_train_1000perClass = datamod.train_dataloader()\n",
    "dataloader_test = datamod.test_dataloader()\n",
    "\n",
    "datasets = ['mnist_single0', 'mnist_single1', 'mnist_10_1', 'mnist_10_8', 'mnist_100_1', 'mnist_100_8', 'mnist_1perClass', 'mnist_10perClass', 'mnist_100perClass', 'mnist_1000perClass']\n",
    " \n",
    "data_loaders = {}\n",
    "for data in datasets:\n",
    "    pm.data_split = data\n",
    "    datamod = datamodule.select_data(pm.params_datamodule)\n",
    "    datamod.setup()\n",
    "    loader = datamod.train_dataloader()\n",
    "    data_loaders[f'{data}'] = loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ab75c-64b0-4266-9567-48682ad90eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754fd1c-15d8-4b95-a5ac-d61192af7c36",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Utils for eval\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0ff86-ce73-4484-bc29-7f64c0abbe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    print(len(dataloader))\n",
    "    classifier_outputs = []\n",
    "    lrn_measures = []\n",
    "    for i,batch in enumerate(tqdm(dataloader)):\n",
    "    #for i,batch in enumerate(dataloader):\n",
    "    #    if i %10 == 0:\n",
    "    #        print(i)\n",
    "        sample,target = batch\n",
    "        sample = sample.cuda()\n",
    "        target = target.cuda()\n",
    "        batch = (sample,target)\n",
    "        \n",
    "        lrn_output, prediction = model.shared_step(batch, i)\n",
    "        lrn_measures.append(run_lrn_measures(lrn_output))\n",
    "        \n",
    "        classifier_outputs.append((torch.argmax(prediction.detach().cpu()), target.detach().cpu().squeeze()))\n",
    "        #from IPython import embed; embed()\n",
    "    classifier_outputs = torch.from_numpy(np.asarray(classifier_outputs))\n",
    "    classifier_measures = run_classifier_measures(classifier_outputs)\n",
    "    \n",
    "    return lrn_measures, classifier_measures\n",
    "\n",
    "def run_lrn_measures(lrn_outputs):\n",
    "    wavefronts = lrn_outputs[0]\n",
    "    amplitudes = lrn_outputs[1] \n",
    "    normalized_amplitudes = lrn_outputs[2]\n",
    "    images = lrn_outputs[3]\n",
    "    normalized_images = lrn_outputs[4]\n",
    "    lrn_target = lrn_outputs[5]\n",
    "\n",
    "    mse_vals = mse(normalized_images.detach(), lrn_target.detach())\n",
    "    psnr_vals = psnr(normalized_images.detach(), lrn_target.detach())\n",
    "    ssim_vals = ssim(normalized_images.detach(), lrn_target.detach()).detach()\n",
    "    return {'mse' : mse_vals.cpu(), 'psnr' : psnr_vals.cpu(), 'ssim' : ssim_vals.cpu()}\n",
    "\n",
    "def run_classifier_measures(classifier_outputs):\n",
    "    predictions, targets = classifier_outputs[:,0], classifier_outputs[:,1]\n",
    "    precision = prec(preds= predictions, target=targets)\n",
    "    recall = rec(preds = predictions, target=targets)\n",
    "    f1_score = f1(preds = predictions, target=targets)\n",
    "    accuracy = acc(preds = predictions, target=targets)\n",
    "    confusion_matrix = cfm(preds=predictions, target = targets)  \n",
    "    return {'prec':precision, 'rec':recall, 'f1':f1_score, 'acc':accuracy, 'cfm':confusion_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae569bd-c9d1-4cd9-b692-a42a753ec0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model in \n",
    "#model = cooperative.CooperativeOptimization.load_from_checkpoint('../my_models/cooperative/test_cooperative_lrnLearned/epoch=1-step=2500.ckpt')\n",
    "model = cooperative.CooperativeOptimization.load_from_checkpoint('../my_models/cooperative/predict_test/epoch=4-step=6250-v2.ckpt')\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6276fc-7e04-40ce-8ea7-de5e6b89161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn_measures, classifier_measures = eval_model(model, data_loaders['mnist_1000perClass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677aa68d-61cf-430b-8beb-47f8b15d3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.lrn.layers[1].phase.squeeze().cpu().detach() % (2*np.pi), cmap='viridis')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486f2b2-1496-40b8-937e-8c02c3e7fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(classifier_measures['cfm'], index = [i for i in \"0123456789\"],\n",
    "                  columns = [i for i in \"0123456789\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 10},cmap='Blues', fmt='g', vmax=1000, vmin=0, linecolor='black', square=True)\n",
    "plt.title(\"Testing\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"testing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de69df-f91b-4635-ae0a-a1dbdc5cad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a good image for comparisons\n",
    "number = 500\n",
    "for i,batch1 in enumerate(dataloader_test):\n",
    "    if i == number:\n",
    "        break\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.imshow(batch1[0].abs().squeeze(), cmap='viridis')\n",
    "ax.grid(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29b5c3-ec18-467d-8a51-2caaaa2c2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,target = batch1\n",
    "sample = sample.cuda()\n",
    "target = target.cuda()\n",
    "batch1 = (sample,target)\n",
    "lrn_output, prediction = model.forward(batch1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00a9b33-8d86-4539-b579-92e71d6e7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lrn_output[3].cpu().squeeze().detach(), cmap='turbo')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964d469-e88d-4e5d-989a-ec7b8213d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825f317-cb3b-4461-a555-9a3573076c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec2d49-db76-460e-a542-83611b33db66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
